Natural Language Processing is one of the most commonly used techniques which is implemented in machine learning applications â€” given the wide range of analysis, extraction, processing and visualizing tasks that it can perform. The primary goal of this exercise  is to tokenize the textual content, remove the stop words, and find the high-frequency words.


Beautifulsoup: To scrape the data from the HTML of a website and it also helps to process only the text from these HTML codes
Regular Expressions: Also known as Regex. It will convert the noise data containing special characters and carry the conversion of uppercase to lowercase characters
NLTK (Natural Language Toolkit): For the tokenization of the sentences into a list of words
In the end, we will look at how the graph looks and also the tokenized word count.
